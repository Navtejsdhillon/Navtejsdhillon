{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOn3zmH4BmykHA+r4Oud1B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navtejsdhillon/Navtejsdhillon/blob/main/ML_linear_Project01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bal8TA1MqxfO",
        "outputId": "b5390d24-179b-4808-bc02-3212d6457254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined build_model and train_model\n"
          ]
        }
      ],
      "source": [
        "#Linear Regression\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def build_model(my_learning_rate):\n",
        "  model=tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(units=1,input_shape=(1,)))\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "            loss=\"mean_squared_error\",\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  return model\n",
        "\n",
        "def train_model(trained_weights,trained_bias,epochs,batch_size):\n",
        "  history=model.fit(x=feature,\n",
        "                    y=label,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,)\n",
        "  trained_weights=model.get_weights()[0]\n",
        "  trained_bias=model.get_weights()[1]\n",
        "  epochs=history.epoch\n",
        "  hist=pd.DataFrame(history.history)\n",
        "  rmse=hist[\"RootMeanSquredError()\"]\n",
        "  return trained_weights,trained_bias,epochs,rmse\n",
        "\n",
        "def plot_the_model(trained_weights,trained_bias,feature,label):\n",
        "  plt.xlabel(\"feature\")\n",
        "  plt.ylabel(\"label\")\n",
        "  plt.scatter(feature,label)\n",
        "  x0=0\n",
        "  y0=trained_bias\n",
        "  x1=feature[-1]\n",
        "  y1=trained_bias + trained_weights*x1\n",
        "  plt.plot([x0,x1],[y0,y1],c='r')\n",
        "  plt.show()\n",
        "\n",
        "def plot_the_loss_curve(epochs,rmse):\n",
        "  plt.xlabel(\"loss\")\n",
        "  plt.ylabel(\"rate\")\n",
        "  plt.plot(epochs,rmse,label=\"Loss\")\n",
        "  plt.legends()\n",
        "  plt.ylim(rmse.min()*0.97,rmse.max())\n",
        "  plt.show()\n",
        "print(\"Defined build_model and train_model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def build_model(learning_rate):\n",
        "  model=tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(units=1,input_shape=(1,)))\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  return model\n",
        "\n",
        "def train_model(model,trained_weights,trained_bias,epochs,batch_size):\n",
        "  history=model.fit(x=features,y=label,epochs=epochs,batch_size=batch_size)\n",
        "  trained_weights=model.get_weights()[0]\n",
        "  trained_bias=model.get_weights()[1]\n",
        "  epochs=history.epoch\n",
        "  hist=pd.DataFrame(history.history)\n",
        "  rmse=hist[\"root_mean_squared_error\"]\n",
        "  return trained_weights,trained_bias,epochs,rmse\n",
        "\n",
        "def plot_the_model(trained_weights,trained_bias,feature,label):\n",
        "  x0=0\n",
        "  y0=trained_bias\n",
        "  x1=feature[-1]\n",
        "  y1=trained_bias + (trained_weights*x1)\n",
        "  plt.xlabel(\"Feature\")\n",
        "  plt.ylabel(\"Label\")\n",
        "  plt.scatter(feature,label,c='r')\n",
        "  plt.plot([x0,x1],[y0,y1],c='k')\n",
        "  plt.show()\n",
        "\n",
        "def plot_the_loss_curve(epochs,rmse):\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.ylim(rmse.min()*0.97,rmse.max())\n",
        "  plt.show()\n",
        "\n",
        "learning_rate=0.01\n",
        "epochs=10\n",
        "batch_size=12\n",
        "\n",
        "my_model=build_model(learning_rate)\n",
        "trained_weights,trained_bias,epochs,rmse=train_model(my_model,my_feature,\n",
        "                                                     my_label,epochs,\n",
        "                                                     my_batch_size)\n",
        "plot_the_model(trained_weights,trained_bias,my_feature,my_label)\n",
        "plot_the_loss_curve(epochs,rmse)\n",
        "\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXBZAnRp97aS",
        "outputId": "c479388f-a39c-44b3-ec82-2f6b0b02c126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Q0JZd2RrDbNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}